ğŸ¥ HealthE â€“ AI-Powered Wellness & Recovery Assistant

HealthE is an AI-powered health companion that predicts recovery time from illness and recommends personalized diet plans using two machine-learning models.
Built as a full-stack application with:

Streamlit Frontend

FastAPI Backend

PostgreSQL (NeonDB) Database

Docker & Docker Compose for complete containerization

Joblib-based ML Models (LightGBM + Logistic Regression)

This project was created as part of a capstone by a team of 6 students.

ğŸš€ Features
ğŸ”§ Recovery Days Prediction

Uses a trained LightGBM regression model + preprocessing scaler to estimate expected recovery time.

ğŸ Diet Plan Recommendation

Uses a trained Logistic Regression classifier to recommend one of several diet plans based on lifestyle + health metrics.

ğŸ“Š History Tracking (Database Logging)

Every prediction is saved to PostgreSQL, allowing the team to view the latest 10 entries inside the sidebar UI.

ğŸ³ Full Dockerized Architecture

Using Docker Compose, the complete system runs with one command:

docker compose up --build

ğŸ“ Clean Modular Folder Structure
HealthE/
â”‚â”€â”€ app.py                     # Streamlit frontend
â”‚â”€â”€ backend/
â”‚     â””â”€â”€ main.py              # FastAPI backend + DB models
â”‚â”€â”€ models/
â”‚     â””â”€â”€ *.joblib             # ML models & scalers
â”‚â”€â”€ data/
â”‚     â””â”€â”€ *.csv                # Original datasets
â”‚â”€â”€ requirements.txt           # Python dependencies
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ Dockerfile                 # Single Dockerfile used for both services
â”‚â”€â”€ .env                       # Environment variables (DB URL, Backend URL)
â””â”€â”€ README.md

ğŸ› ï¸ Tech Stack
Layer	Technology
Frontend	Streamlit
Backend	FastAPI
ML	LightGBM, Scikit-Learn, Joblib
Database	PostgreSQL (Neon)
Orchestration	Docker Compose
Language	Python 3.10
âš™ï¸ Running the Project
âœ… Setup .env

Inside your project root:

# Backend
DB_URL=postgresql://<user>:<password>@<host>/<database>
BACKEND_URL=http://backend:8000

# Frontend
STREAMLIT_SERVER_PORT=8501

ğŸ³ Run everything with Docker Compose
docker compose up --build


Services will start:

Service	URL
Frontend (Streamlit)	http://localhost:8501

Backend (FastAPI)	http://localhost:8000/docs
ğŸ”Œ API Endpoints (FastAPI)
â• POST /log_prediction

Stores prediction + input features in DB.

ğŸ“œ GET /history?limit=10

Returns the 10 most recent predictions saved.

All endpoints are visible in Swagger UI:

ğŸ‘‰ http://localhost:8000/docs

ğŸ¤– ML Models
1ï¸âƒ£ Recovery Time Model

Algorithm: LightGBM Regressor

Input features: Age, BMI, condition, sleep hours, smoking status, severity, etc.

Output: Predicted recovery days

2ï¸âƒ£ Diet Recommendation Model

Algorithm: Logistic Regression

Output Categories:

Balanced Diet

High Protein

Keto

Low Carb

Low Fat

Vegan

Both models are pre-trained and stored in models/*.joblib.

ğŸ“Š Data Logging & History

Every prediction sent from the UI is logged to PostgreSQL via backend FastAPI.

Example stored entry:

{
  "prediction_type": "recovery_days",
  "inputs": { ... },
  "output": { "recovery_days": 7.5 },
  "created_at": "2025-02-05T18:40:31"
}

ğŸ“¸ Screenshots

(Add later)

ğŸŸ© Streamlit UI  
ğŸŸ¦ FastAPI Docs  
ğŸŸª Database with stored predictions  

ğŸ§ª Testing (Optional)

Run backend only:

uvicorn backend.main:app --reload


Run frontend only:

streamlit run app.py

ğŸ§‘â€ğŸ¤â€ğŸ§‘ Project Contributors

ğŸ’¡ Developed by 6 students from Durham College
âš™ï¸ ML, backend, frontend, and DevOps contributions distributed across the team.

â­ If you like this project, give it a star!

This helps the team demonstrate good engineering practices, containerization, and full-stack ML deployment.